{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T07:58:52.146800Z",
          "iopub.status.busy": "2024-11-11T07:58:52.146367Z",
          "iopub.status.idle": "2024-11-11T07:59:33.218787Z",
          "shell.execute_reply": "2024-11-11T07:59:33.217297Z",
          "shell.execute_reply.started": "2024-11-11T07:58:52.146763Z"
        },
        "id": "xPpTENfOar84",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --user pycaret -full\n",
        "!pip install numba==0.53"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T07:59:33.222421Z",
          "iopub.status.busy": "2024-11-11T07:59:33.221487Z",
          "iopub.status.idle": "2024-11-11T07:59:42.932894Z",
          "shell.execute_reply": "2024-11-11T07:59:42.931717Z",
          "shell.execute_reply.started": "2024-11-11T07:59:33.222374Z"
        },
        "id": "TfdP_ZpaHvkN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import average_precision_score, accuracy_score\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pathlib\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn\n",
        "\n",
        "base_dir = pathlib.Path('/content/drive/MyDrive/Ikoma Paper')\n",
        "dataset_path = base_dir / 'dataset.csv'\n",
        "dataset_df = pd.read_csv(dataset_path)\n",
        "save_dir = base_dir / '5fold'\n",
        "save_dir.mkdir(exist_ok=True, parents=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFl0PQB0ar89",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "feature_gene = dataset_df.columns[2:-9]\n",
        "feature_gene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYsvnUxVar8-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "display(dataset_df['fold'].value_counts())\n",
        "print(len(feature_gene))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8qMdMmqcxZk"
      },
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "We trained and compared the following machine learning models:\n",
        "\n",
        "*   RandomForest\n",
        "*   LightGBM\n",
        "*   XGBoost\n",
        "*   Logistic Regression\n",
        "*   SVM\n",
        "*   KNN\n",
        "\n",
        "Each model was trained using a 5-fold cross-validation approach. The performance of each model was evaluated using the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-11T07:59:44.163187Z",
          "iopub.status.busy": "2024-11-11T07:59:44.162011Z"
        },
        "id": "ApI32YH3ar8_",
        "outputId": "60749ad7-cced-4239-98d9-558688bf4029",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest, 0\n",
            "RandomForest, 1\n",
            "RandomForest, 2\n",
            "RandomForest, 3\n",
            "RandomForest, 4\n",
            "LightGBM, 0\n",
            "LightGBM, 1\n",
            "LightGBM, 2\n",
            "LightGBM, 3\n",
            "LightGBM, 4\n",
            "XGBoost, 0\n",
            "XGBoost, 1\n",
            "XGBoost, 2\n",
            "XGBoost, 3\n",
            "XGBoost, 4\n",
            "Logistic Regression, 0\n",
            "Logistic Regression, 1\n",
            "Logistic Regression, 2\n",
            "Logistic Regression, 3\n",
            "Logistic Regression, 4\n",
            "SVM, 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert column names to strings\n",
        "dataset_df.columns = dataset_df.columns.astype(str)\n",
        "\n",
        "# Define each model (LightGBM and XGBoost are set to use GPU)\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LightGBM': LGBMClassifier(device='gpu'),\n",
        "    'XGBoost': XGBClassifier(tree_method='gpu_hist'),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {model_name: {\"fpr\": [], \"tpr\": [], \"aucs\": [], \"mean_fpr\": np.linspace(0, 1, 100)} for model_name in models.keys()}\n",
        "\n",
        "# Prepare the figure for plotting\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Plot the ROC curve for each model\n",
        "for model_name, model in models.items():\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    mean_fpr = results[model_name][\"mean_fpr\"]\n",
        "\n",
        "    for fold in range(5):\n",
        "        print(f'{model_name}, {fold}')\n",
        "\n",
        "        # Split training and validation data\n",
        "        train_df = dataset_df[dataset_df['fold'] != fold]\n",
        "        valid_df = dataset_df[dataset_df['fold'] == fold]\n",
        "\n",
        "        train_X, train_y = train_df[feature_gene], train_df['label']\n",
        "        valid_X, valid_y = valid_df[feature_gene], valid_df['label']\n",
        "\n",
        "        # Train the model\n",
        "        trained_model = model.fit(train_X, train_y)\n",
        "        pred = trained_model.predict_proba(valid_X)[:, 1]\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, _ = roc_curve(valid_y, pred)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
        "        interp_tpr[0] = 0.0\n",
        "        tprs.append(interp_tpr)\n",
        "        aucs.append(roc_auc)\n",
        "\n",
        "        # Save FPR, TPR, and AUC for each fold\n",
        "        results[model_name][\"fpr\"].append(fpr)\n",
        "        results[model_name][\"tpr\"].append(tpr)\n",
        "        results[model_name][\"aucs\"].append(roc_auc)\n",
        "\n",
        "    # Compute and store the mean ROC curve\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    results[model_name][\"mean_tpr\"] = mean_tpr\n",
        "    results[model_name][\"mean_auc\"] = mean_auc\n",
        "    results[model_name][\"std_auc\"] = std_auc\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.plot(mean_fpr, mean_tpr, label=f'{model_name} (AUC = {mean_auc:.2f} Â± {std_auc:.2f})')\n",
        "\n",
        "# Finalize the ROC curve plot\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Save results to a file (e.g., using np.savez)\n",
        "np.savez(\"roc_data.npz\", results=results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Convert column names to strings\n",
        "dataset_df.columns = dataset_df.columns.astype(str)\n",
        "\n",
        "# Dictionary to store results\n",
        "result_dict = defaultdict(list)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for fold in range(5):\n",
        "    train_df = dataset_df[dataset_df['fold'] != fold]\n",
        "    valid_df = dataset_df[dataset_df['fold'] == fold]\n",
        "\n",
        "    train_X, train_y = train_df[feature_gene], train_df['label']\n",
        "    valid_X, valid_y = valid_df[feature_gene], valid_df['label']\n",
        "\n",
        "    # Define models (LightGBM and XGBoost are set to use GPU)\n",
        "    models = {\n",
        "        'RandomForest': RandomForestClassifier(),\n",
        "        'LightGBM': LGBMClassifier(device='gpu'),\n",
        "        'XGBoost': XGBClassifier(tree_method='gpu_hist'),\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC(probability=True),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    # Define evaluation metrics\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score,\n",
        "        'Balanced Accuracy': balanced_accuracy_score,\n",
        "        'ROC_AUC': roc_auc_score,\n",
        "        'F1_Score': f1_score,\n",
        "        'Precision': precision_score,\n",
        "        'Recall': recall_score\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for model_name, model in models.items():\n",
        "        print(fold, model_name)\n",
        "        trained_model = model.fit(train_X, train_y)\n",
        "        pred = trained_model.predict_proba(valid_X)[:, 1]\n",
        "\n",
        "        # Compute evaluation metrics\n",
        "        for metric_name, metric_func in metrics.items():\n",
        "            if metric_name == 'ROC_AUC':\n",
        "                metric_value = metric_func(valid_y, pred)\n",
        "            else:\n",
        "                metric_value = metric_func(valid_y, (pred > 0.1005).astype(int))\n",
        "                \n",
        "            result_dict['model_name'].append(model_name)\n",
        "            result_dict['metric_name'].append(metric_name)\n",
        "            result_dict['score'].append(metric_value)\n",
        "            result_dict['fold'].append(fold)\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "result_df = pd.DataFrame(result_dict)\n",
        "\n",
        "# Visualization of results\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.barplot(data=result_df, x='metric_name', y='score', hue='model_name')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xlabel('Metric Name')\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4201966,
          "sourceId": 7252245,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30627,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
