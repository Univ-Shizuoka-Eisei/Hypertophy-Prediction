{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview and Preprocessing\n",
    "\n",
    "The dataset is assumed to have columns including `fold`, `label`, and a set of gene features. The variable `feature_gene` contains the list of gene features used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, recall_score, precision_score\n",
    "\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "base_dir = pathlib.Path('/content/drive/MyDrive/Ikoma Paper')\n",
    "dataset_path = base_dir / 'dataset.csv'\n",
    "dataset_df = pd.read_csv(dataset_path)\n",
    "save_dir = base_dir / '5fold'\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "feature_gene = dataset_df.columns[2:-9]\n",
    "\n",
    "# Display the distribution of folds and the number of gene features\n",
    "display(dataset_df['fold'].value_counts())\n",
    "print('Number of features:', len(feature_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We define functions for training the model for a given fold and for evaluating the model. The training uses early stopping based on validation AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_score_df(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute performance metrics on the given data using the provided model.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features (numpy array or DataFrame)\n",
    "    - y: True labels\n",
    "    - model: Trained LightGBM model\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing performance metrics and model predictions.\n",
    "    \"\"\"\n",
    "    score_dic = {}\n",
    "\n",
    "    # Predict continuous probabilities\n",
    "    pred = model.predict(X)\n",
    "    score_dic['ROC-AUC'] = [roc_auc_score(y, pred)]\n",
    "\n",
    "    # Set the threshold (determined from prior analysis)\n",
    "    optimal_th = 0.1005\n",
    "    pred_label = np.where(pred > optimal_th, 1, 0)\n",
    "    score_dic['Acc'] = [accuracy_score(y, pred_label)]\n",
    "    score_dic['BA'] = [balanced_accuracy_score(y, pred_label)]\n",
    "    score_dic['Recall'] = [recall_score(y, pred_label)]\n",
    "    score_dic['Precision'] = [precision_score(y, pred_label)]\n",
    "\n",
    "    return pd.DataFrame(score_dic), pred\n",
    "\n",
    "def train_model(fold):\n",
    "    \"\"\"\n",
    "    Train a LightGBM model using a specific fold for validation.\n",
    "\n",
    "    Parameters:\n",
    "    - fold: The fold number used as the validation set.\n",
    "    \"\"\"\n",
    "    # Split the data into training and validation sets\n",
    "    train_in = dataset_df[dataset_df['fold'] != fold]\n",
    "    valid = dataset_df[dataset_df['fold'] == fold]\n",
    "\n",
    "    train_X, train_y = train_in[feature_gene], train_in['label']\n",
    "    valid_X, valid_y = valid[feature_gene], valid['label']\n",
    "\n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgbm.Dataset(train_X, label=train_y, free_raw_data=False)\n",
    "    valid_data = lgbm.Dataset(valid_X, label=valid_y, free_raw_data=False)\n",
    "\n",
    "    # Define model parameters\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'seed': 42,\n",
    "    }\n",
    "\n",
    "    num_round = 10000\n",
    "    bst = lgbm.train(\n",
    "        params=param,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=num_round,\n",
    "        valid_sets=[(valid_data)],\n",
    "        callbacks=[\n",
    "            lgbm.early_stopping(stopping_rounds=100, verbose=True),\n",
    "            lgbm.log_evaluation(5),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Optionally, save the model\n",
    "    # file = save_dir + f'fold{fold}.pkl'\n",
    "    # pickle.dump(bst, open(file, 'wb'))\n",
    "\n",
    "# Train the model for each fold (5-fold cross-validation)\n",
    "for i in range(5):\n",
    "    train_model(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Here we load the trained models from each fold, compute performance metrics, and generate out-of-fold (OOF) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = base_dir / 'ikoma/lightGBM/5fold'\n",
    "score_df = pd.DataFrame()\n",
    "oof_df = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    model = pickle.load(open(save_dir + f'fold{i}.pkl', 'rb'))\n",
    "    X = dataset_df[dataset_df['fold'] == i][feature_gene].values\n",
    "    y = dataset_df[dataset_df['fold'] == i]['label'].reset_index(drop=True)\n",
    "    res_df, pred = get_fold_score_df(X, y, model)\n",
    "    res_df['fold'] = i\n",
    "\n",
    "    _oof_df = pd.DataFrame()\n",
    "    _oof_df['pred'] = pred\n",
    "    _oof_df['label'] = y\n",
    "    _oof_df['fold'] = i\n",
    "    _oof_df['DOSE_LEVEL'] = dataset_df[dataset_df['fold'] == i]['DOSE_LEVEL'].reset_index(drop=True)\n",
    "    _oof_df['SACRI_PERIOD'] = dataset_df[dataset_df['fold'] == i]['SACRI_PERIOD'].reset_index(drop=True)\n",
    "    _oof_df['COMPOUND_NAME'] = dataset_df[dataset_df['fold'] == i]['COMPOUND_NAME'].reset_index(drop=True)\n",
    "    oof_df = pd.concat([oof_df, _oof_df]).reset_index(drop=True)\n",
    "\n",
    "    score_df = pd.concat([score_df, res_df])\n",
    "\n",
    "print('Average performance metrics')\n",
    "print(score_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Analysis for Feature Importance\n",
    "\n",
    "We use SHAP (SHapley Additive exPlanations) to determine the absolute importance of each gene feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configure for either analyzing all data or each fold separately\n",
    "ALL_DATA = True\n",
    "mean_all_importance_df = pd.DataFrame()\n",
    "\n",
    "all_shap = []\n",
    "for fold in range(5):\n",
    "    if ALL_DATA:\n",
    "        X = dataset_df[feature_gene]\n",
    "    else:\n",
    "        X = dataset_df[dataset_df['fold'] == fold][feature_gene]\n",
    "\n",
    "    model = pickle.load(open(save_dir + f'fold{fold}.pkl', 'rb'))\n",
    "\n",
    "    # Initialize SHAP JavaScript visualization (if needed in notebooks)\n",
    "    shap.initjs()\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    # Save only the SHAP values corresponding to the positive class\n",
    "    all_shap.append(shap_values[1].astype(np.float16))\n",
    "\n",
    "    # Compute mean absolute SHAP values for each feature\n",
    "    mean_shap = np.abs(shap_values[1]).mean(axis=0)\n",
    "    importance_df = pd.DataFrame([X.columns.tolist(), mean_shap.tolist()]).T\n",
    "    importance_df.columns = ['Feature', f'SHAP Absolute Importance fold{fold}']\n",
    "\n",
    "    mean_all_importance_df = pd.concat([mean_all_importance_df, importance_df], axis=1)\n",
    "\n",
    "# Process and compute the overall mean SHAP importance for each feature\n",
    "mean_all_importance_df = mean_all_importance_df.T.drop_duplicates().T\n",
    "mean_all_importance_df.index = mean_all_importance_df['Feature']\n",
    "mean_all_importance_df = mean_all_importance_df.drop('Feature', axis=1)\n",
    "mean_all_importance_df['MEAN SHAP Importance'] = mean_all_importance_df.mean(axis=1)\n",
    "mean_all_importance_df = mean_all_importance_df.sort_values('MEAN SHAP Importance', ascending=False)\n",
    "mean_all_importance_df['Feature'] = mean_all_importance_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Model Performance\n",
    "\n",
    "Below is a function to generate a grouped bar plot comparing the performance of different classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def create_performance_plot(data_path):\n",
    "    \"\"\"\n",
    "    Create a performance plot based on the metrics contained in an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path: Path to the Excel file containing performance metrics.\n",
    "\n",
    "    Returns:\n",
    "    - Matplotlib plot object.\n",
    "    \"\"\"\n",
    "    # Set the theme for the plot\n",
    "    sns.set_theme(\n",
    "        context='paper',\n",
    "        style='whitegrid',\n",
    "        rc={\n",
    "            'font.size': 12,\n",
    "            'axes.titlesize': 12,\n",
    "            'axes.labelsize': 12,\n",
    "            'xtick.labelsize': 8,\n",
    "            'ytick.labelsize': 8\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(data_path)\n",
    "\n",
    "    # Define metric names\n",
    "    metrics = {\n",
    "        'Accuracy': 'Accuracy',\n",
    "        'Balanced Accuracy': 'Balanced Accuracy',\n",
    "        'ROC_AUC': 'ROC-AUC',\n",
    "        'F1_Score': 'F1 Score',\n",
    "        'Precision': 'Precision',\n",
    "        'Recall': 'Recall'\n",
    "    }\n",
    "\n",
    "    # Aggregate results\n",
    "    results = []\n",
    "    for metric in metrics.keys():\n",
    "        metric_data = df.groupby('Classification model')[metric].agg(['mean', 'std']).reset_index()\n",
    "        metric_data['Metric'] = metrics[metric]\n",
    "        results.append(metric_data)\n",
    "\n",
    "    results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Create the grouped bar plot\n",
    "    plt.figure(figsize=(7.5, 3.5))\n",
    "\n",
    "    # Define colors for models\n",
    "    model_colors = {\n",
    "        'RandomForest': '#4878CF',\n",
    "        'LightGBM': '#6ACC65',\n",
    "        'XGBoost': '#D65F5F',\n",
    "        'Logistic Regression': '#B47CC7',\n",
    "        'SVM': '#C4AD66',\n",
    "        'KNN': '#77BEDB'\n",
    "    }\n",
    "\n",
    "    ax = plt.gca()\n",
    "    n_metrics = len(metrics)\n",
    "    n_models = len(model_colors)\n",
    "    bar_width = 0.8 / n_models\n",
    "\n",
    "    for i, (model, color) in enumerate(model_colors.items()):\n",
    "        model_data = results_df[results_df['Classification model'] == model]\n",
    "        x = np.arange(n_metrics) + i * bar_width - (n_models - 1) * bar_width / 2\n",
    "\n",
    "        # Plot bars\n",
    "        bars = ax.bar(x, model_data['mean'], bar_width, label=model, color=color)\n",
    "        # Add error bars\n",
    "        ax.errorbar(x, model_data['mean'], yerr=model_data['std'],\n",
    "                    fmt='none', color='black', capsize=3, capthick=1, linewidth=1)\n",
    "\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(np.arange(n_metrics), list(metrics.values()), rotation=30)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, fontsize=10)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return plt\n",
    "\n",
    "# Example usage\n",
    "# plt_obj = create_performance_plot('Table S2.xlsx')\n",
    "# plt_obj.savefig('model_performance.png', dpi=300, bbox_inches='tight')\n",
    "# plt_obj.close()\n",
    "plt_obj = create_performance_plot('contentTable S2.xlsx')\n",
    "plt_obj.savefig('model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt_obj.show()\n",
    "plt_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Top Feature Importances\n",
    "\n",
    "We display the top 20 features ranked by mean absolute SHAP importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Feature Importance Visualization\n",
    "\n",
    "The following section creates a bar plot for the top 10 gene features based on SHAP importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context='paper',\n",
    "    style='whitegrid', \n",
    "    rc={\n",
    "        'font.size': 10,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'xtick.labelsize': 8,\n",
    "        'ytick.labelsize': 8\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "ax = sns.barplot(data=mean_all_importance_df.head(10), x='Feature', y='MEAN SHAP Importance', color='black')\n",
    "\n",
    "# Set axis spine and tick colors\n",
    "ax.spines['top'].set_color('#000000')\n",
    "ax.spines['bottom'].set_color('#000000')\n",
    "ax.spines['left'].set_color('#000000')\n",
    "ax.spines['right'].set_color('#000000')\n",
    "ax.tick_params(axis='x', colors='#000000')\n",
    "ax.tick_params(axis='y', colors='#000000')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(None)\n",
    "plt.savefig('figure2A.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging SHAP Values Across Folds\n",
    "\n",
    "We average the SHAP values obtained from all folds for further interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap_values = np.zeros(shap_values[1].shape)\n",
    "for a in all_shap:\n",
    "    all_shap_values += a\n",
    "all_shap_values /= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Dependence Plots for Top Features\n",
    "\n",
    "For the top 10 features, we create SHAP dependence plots (box plots) to visualize the feature effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 10 genes by SHAP importance\n",
    "mean_top10_genes = mean_all_importance_df.head(10).index\n",
    "\n",
    "sns.set_theme(\n",
    "    context='paper',\n",
    "    style='whitegrid', \n",
    "    rc={\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'xtick.labelsize': 8,\n",
    "        'ytick.labelsize': 8\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create subplots for dependence plots\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    shap.dependence_plot(\n",
    "        ind=mean_top10_genes[i],\n",
    "        shap_values=all_shap_values,\n",
    "        features=X,\n",
    "        ax=ax,\n",
    "        interaction_index=None,\n",
    "        show=False,\n",
    "        dot_size=0.5,\n",
    "    )\n",
    "    # Add vertical reference lines at -1 and 1\n",
    "    ax.axvline(x=-1, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n",
    "    ax.axvline(x=1, color='gray', linestyle='--', alpha=0.5, linewidth=0.5)\n",
    "    ax.set_xticks([-3, -1, 0, 1, 3])\n",
    "    ax.set_xticklabels(['-3', '-1', '0', '1', '3'])\n",
    "\n",
    "    if i == 0 or i == 5:\n",
    "        ax.set_ylabel('SHAP value', fontsize=16)\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    ax.spines['top'].set_color('#000000')\n",
    "    ax.spines['bottom'].set_color('#000000')\n",
    "    ax.spines['left'].set_color('#000000')\n",
    "    ax.spines['right'].set_color('#000000')\n",
    "    ax.tick_params(axis='x', colors='#000000')\n",
    "    ax.tick_params(axis='y', colors='#000000')\n",
    "    ax.tick_params(labelsize=10)\n",
    "    ax.set_xlabel(f'$\\it{{{mean_top10_genes[i]}}}$', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2B.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Analysis\n",
    "\n",
    "The following code examines a subset of the data (e.g., high dose and 28-day period) and extracts compounds with consistent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the 29 day period and High dose\n",
    "high_28day_df = dataset_df.query('SACRI_PERIOD==29 day').query('DOSE_LEVEL==High')\n",
    "\n",
    "# Identify compounds where all samples have the same label\n",
    "compound_labels = high_28day_df.groupby('COMPOUND_NAME')['label'].nunique()\n",
    "consistent_compounds = compound_labels[compound_labels == 1].index\n",
    "consistent_df = high_28day_df[high_28day_df['COMPOUND_NAME'].isin(consistent_compounds)]\n",
    "\n",
    "# From the group with label 0, select the compound with the highest value of Cyp2b1\n",
    "zero_label_df = consistent_df[consistent_df['label'] == 0]\n",
    "max_cyp2b1_compound = zero_label_df.loc[zero_label_df['Cyp2b1'].idxmax()]\n",
    "\n",
    "print(f'COMPOUND_NAME: {max_cyp2b1_compound['COMPOUND_NAME']}')\n",
    "print(f'Cyp2b1: {max_cyp2b1_compound['Cyp2b1']}')\n",
    "print(f'index: {max_cyp2b1_compound.name}')\n",
    "\n",
    "# Display the top 10 compounds based on Cyp2b1 for zero label\n",
    "print(zero_label_df.nlargest(10, 'Cyp2b1')[['COMPOUND_NAME', 'Cyp2b1', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Force and Waterfall Plots\n",
    "\n",
    "We generate a force plot and a waterfall plot for a selected test data sample to illustrate the SHAP value contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context='paper',\n",
    "    style='white',\n",
    "    rc={\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'axes.labelsize': 14,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12\n",
    "    }\n",
    ")\n",
    "\n",
    "# Example for a test sample (n = 1924)\n",
    "n = 1924\n",
    "fig = plt.gcf()\n",
    "# Create a force plot (if running in a notebook with proper JS support)\n",
    "index = np.argsort(np.abs(shap_values[1][n]))\n",
    "result = np.take_along_axis(shap_values[1][n], index, axis=0)\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                result[-1000],\n",
    "                dataset_df[feature_gene].round(3).iloc[n, index[-1000]],\n",
    "                matplotlib=True)\n",
    "plt.savefig('clomipramine_1.jpg')\n",
    "plt.show()\n",
    "\n",
    "# Generate a waterfall plot for the same test sample\n",
    "n = 1924\n",
    "fig = plt.gcf()\n",
    "index = np.argsort(np.abs(shap_values[1][n]))\n",
    "result = np.take_along_axis(shap_values[1][n], index, axis=0)\n",
    "shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1],\n",
    "                                       result[-1000],\n",
    "                                       dataset_df[feature_gene].iloc[n, index[-1000]])\n",
    "plt.savefig('disopyramide.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n",
    "\n",
    "The following function computes the sigmoid of a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example computation\n",
    "print('Sigmoid(-0.694) =', sigmoid(-0.694))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This document detailed the process of training and evaluating a LightGBM model for dose-response classification and interpreting the results using SHAP-based feature importance. Further analyses and visualizations can be conducted as required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
